{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2db98386-b2a6-4883-9781-bfd19f7fb505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load your saved model\n",
    "model = load_model(\"fight_detection_model.h5\")\n",
    "\n",
    "# Parameters\n",
    "SEGMENT_FRAMES = 10    # number of frames per segment\n",
    "THRESHOLD = 0.6        # violence probability threshold\n",
    "\n",
    "def extract_frames_from_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (224,224))\n",
    "        frame = frame / 255.0\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "def detect_fights_in_video(video_path):\n",
    "    frames = extract_frames_from_video(video_path)\n",
    "    num_frames = len(frames)\n",
    "    \n",
    "    # Copy original frames for visualization\n",
    "    frames_show = (frames * 255).astype(np.uint8).copy()\n",
    "    \n",
    "    # Predict in segments\n",
    "    for start in range(0, num_frames - SEGMENT_FRAMES + 1, SEGMENT_FRAMES):\n",
    "        segment = frames[start:start + SEGMENT_FRAMES]\n",
    "        segment_input = np.expand_dims(segment, axis=0)\n",
    "        pred = model.predict(segment_input)[0]\n",
    "        violence_prob = pred[0]\n",
    "        alert = \"Fight Detected!\" if violence_prob > THRESHOLD else \"Safe\"\n",
    "        \n",
    "        # Overlay alert on segment frames\n",
    "        for i in range(start, start + SEGMENT_FRAMES):\n",
    "            frame = frames_show[i]\n",
    "            color = (0,0,255) if violence_prob > THRESHOLD else (0,255,0)\n",
    "            cv2.putText(frame, alert, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "            if violence_prob > THRESHOLD:\n",
    "                # Draw bounding box around center of frame\n",
    "                h, w, _ = frame.shape\n",
    "                cv2.rectangle(frame, (w//4,h//4), (3*w//4,3*h//4), color, 3)\n",
    "    \n",
    "    # Play video with overlay\n",
    "    for frame in frames_show:\n",
    "        cv2.imshow(\"Fight Detection\", frame)\n",
    "        if cv2.waitKey(50) & 0xFF == ord('q'):  # 20 FPS approx\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "video_path = \"test4.mp4\"  # replace with your video path\n",
    "detect_fights_in_video(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817deaa-0d5e-4804-8294-764ca4973b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4812e32-bbab-427a-83fd-55d0c6dd75df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
